# LLM Configuration
# Copy this file to .env and fill in your values

# Provider: openai | anthropic | azure | ollama | or any LiteLLM-supported provider
LLM_PROVIDER=openai

# Model name (provider-specific)
LLM_MODEL=gpt-4o

# API key (leave blank for local models like Ollama)
LLM_API_KEY=

# Custom base URL (optional â€” for Azure, Ollama, or self-hosted endpoints)
# LLM_API_BASE=http://localhost:11434
